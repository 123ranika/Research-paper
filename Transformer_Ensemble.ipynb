{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/123ranika/Research-paper/blob/default/Transformer_Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_VFoKDGfYm5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the models we'll use in our ensemble\n",
        "model_names = [\n",
        "    \"ai4bharat/indic-bert\",\n",
        "    \"bert-base-multilingual-uncased\",\n",
        "    \"neuralspace-reverie/indic-transformers-hi-bert\",\n",
        "    \"xlm-roberta-base\"\n",
        "]\n",
        "\n",
        "# Load and preprocess the datasets\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Ensure 'text' column exists and contains string data\n",
        "    if 'text' not in df.columns:\n",
        "        raise ValueError(f\"'text' column not found in {file_path}\")\n",
        "    df['text'] = df['text'].astype(str)\n",
        "    return df\n",
        "\n",
        "try:\n",
        "    train_df = pd.read_csv('/kaggle/input/devanagari-a/SubTask-A-train.csv')\n",
        "    val_df = pd.read_csv('/kaggle/input/devanagari-a/Task-A(indextext)val.csv')\n",
        "    test_df = pd.read_csv('/kaggle/input/devanagari-a/Task-A(indextext)test.csv')\n",
        "    temp_df = pd.read_csv('/kaggle/input/devanagari-a/Task-A(indexlabel)val.csv')\n",
        "    val_df['label'] = temp_df['label']\n",
        "except Exception as e:\n",
        "    print(f\"Error loading data: {e}\")\n",
        "    raise\n",
        "\n",
        "# Combine train and validation for stratified split\n",
        "combined_df = pd.concat([train_df, val_df], ignore_index=True)\n",
        "\n",
        "# Perform stratified split\n",
        "train_df, val_df = train_test_split(combined_df, test_size=0.1, stratify=combined_df['label'], random_state=42)\n",
        "\n",
        "# Convert to Hugging Face datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Helper function for computing metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Function to train a single model\n",
        "def train_model(model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        # Ensure 'text' is a list of strings\n",
        "        texts = [str(text) for text in examples['text']]\n",
        "        return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "    tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_{model_name.split('/')[-1]}\",\n",
        "        num_train_epochs=5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=64,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f'./logs_{model_name.split(\"/\")[-1]}',\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "    )\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_val,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    return trainer, tokenizer\n",
        "\n",
        "# Train all models\n",
        "trained_models = []\n",
        "for model_name in model_names:\n",
        "    print(f\"Training model: {model_name}\")\n",
        "    try:\n",
        "        trainer, tokenizer = train_model(model_name)\n",
        "        trained_models.append((trainer, tokenizer))\n",
        "    except Exception as e:\n",
        "        print(f\"Error training model {model_name}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Rest of the code remains the same...\n",
        "\n",
        "# Function to get predictions from a single model\n",
        "def get_predictions(trainer, tokenizer, dataset):\n",
        "    def tokenize_function(examples):\n",
        "        # Ensure 'text' is a list of strings\n",
        "        texts = [str(text) for text in examples['text']]\n",
        "        return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "    predictions = trainer.predict(tokenized_dataset)\n",
        "    return predictions.predictions\n",
        "\n",
        "# Get predictions from all models\n",
        "all_predictions = []\n",
        "for trainer, tokenizer in trained_models:\n",
        "    print(f\"Getting predictions from model: {trainer.model.name_or_path}\")\n",
        "    try:\n",
        "        predictions = get_predictions(trainer, tokenizer, test_dataset)\n",
        "        all_predictions.append(predictions)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting predictions from model {trainer.model.name_or_path}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Ensemble predictions using majority voting\n",
        "if all_predictions:\n",
        "    ensemble_predictions = np.stack(all_predictions)\n",
        "\n",
        "    # Apply majority voting along the model axis for each sample\n",
        "    majority_votes = np.apply_along_axis(lambda x: np.bincount(x).argmax(), 0, ensemble_predictions.argmax(axis=2))\n",
        "\n",
        "    # Create a DataFrame with predictions\n",
        "    results_df = pd.DataFrame({\n",
        "        'text': test_df['text'],\n",
        "        'label': majority_votes\n",
        "    })\n",
        "\n",
        "    # Save the results to a new CSV file\n",
        "    #results_df.to_csv('ensemble_test_results.csv', index=False)\n",
        "    print(\"Ensemble predictions have been saved to 'ensemble_test_results.csv'\")\n",
        "else:\n",
        "    print(\"No predictions were made. Check the errors above.\")\n",
        "\n"
      ]
    }
  ]
}